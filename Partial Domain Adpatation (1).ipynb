{"cells":[{"cell_type":"markdown","metadata":{"id":"t2RxZ9FZy0An"},"source":["**Partial domain Adpatation**"]},{"cell_type":"markdown","source":["Partial Domain Adaptation (PDA) is a domain adaptation scenario where the target domain's label space is a subset of the source domain's label space. Unlike traditional domain adaptation, PDA addresses the challenge of negative transfer caused by mismatched classes between the source and target domains"],"metadata":{"id":"R3pfgsHQc6yX"}},{"cell_type":"markdown","metadata":{"id":"Ht--dqwIzhzT"},"source":["**Class Conditional Alignment (CCA-PDA)**"]},{"cell_type":"markdown","metadata":{"id":"NuQNgZY71MOi"},"source":["CCA - is a well-designed method for partial domain adaptation that directly tackles the class mismatch issue between source and target domains.\n","\n","\n","It uses a **multi-class adversarial loss** to perform this alignment, ensuring that only the shared classes between source and target are emphasized. This helps avoid **negative transfer** from source-only classes."]},{"cell_type":"markdown","metadata":{"id":"Lcw0P-MGzLCO"},"source":["**Imports**"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":10578,"status":"ok","timestamp":1750088120418,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"},"user_tz":300},"id":"ZbOWpQC8zMUD"},"outputs":[],"source":["import os\n","import kagglehub\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchvision.datasets import ImageFolder\n","\n","import PIL.Image as Image\n","\n","\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1750088120457,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"},"user_tz":300},"id":"7DMQVp2-zRce","outputId":"a3b837af-4e6b-4cff-a27f-e3e32518599f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["# Setup device-agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"markdown","metadata":{"id":"_fkNF7e0zTsT"},"source":["**Datasets**"]},{"cell_type":"markdown","metadata":{"id":"2nKWseU90SNC"},"source":["**Caltech** as the source and **Office-31** as the target is a classic partial domain adaptation (PDA) scenario, since Caltech has a broader label space (256 classes) while Office-31 has only 31. This means you’ll need to filter out the irrelevant Caltech classes to avoid negative transfer."]},{"cell_type":"markdown","metadata":{"id":"G7G7S-hJzXhz"},"source":["upload caltech source from kaggle"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":111916,"status":"ok","timestamp":1750088232375,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"},"user_tz":300},"id":"GaQBzwsOzWwO","outputId":"77a8f1f9-f7a8-41a2-e993-1fee78a22707"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/jessicali9530/caltech256?dataset_version_number=2...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.12G/2.12G [01:40<00:00, 22.6MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/jessicali9530/caltech256/versions/2\n"]}],"source":["# Download latest version\n","source_path = kagglehub.dataset_download(\"jessicali9530/caltech256\")\n","\n","print(\"Path to dataset files:\", source_path)\n"]},{"cell_type":"markdown","metadata":{"id":"kR7Qde-Azb4r"},"source":["upload zipped office-31 file from google drive downloaded from mega.nz"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"id":"TSCiBsibzdqL","executionInfo":{"status":"ok","timestamp":1750088237128,"user_tz":300,"elapsed":4749,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"outputs":[],"source":["# Where i downloaded office-31\n","# https://mega.nz/file/dSpjyCwR#9ctB4q1RIE65a4NoJy0ox3gngh15cJqKq1XpOILJt9s\n","\n","!unzip -q \"/content/drive/MyDrive/office-31/Original_images1.zip\" -d /content/office31"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"JcxAz8uXzgPj","executionInfo":{"status":"ok","timestamp":1750088237133,"user_tz":300,"elapsed":1,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"outputs":[],"source":["# Load dataset\n","dataset_path = \"/content/office31\"\n","\n","target_amazon_path = os.path.join(dataset_path, \"Original_images/amazon\")\n","target_dslr_path = os.path.join(dataset_path, \"Original_images/dslr\")\n","target_webcam_path = os.path.join(dataset_path, \"Original_images/webcam\")\n"]},{"cell_type":"markdown","metadata":{"id":"8_Lr-xnT0ZaK"},"source":["**Data Processing**"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"josw68i7zUhW","executionInfo":{"status":"ok","timestamp":1750088237164,"user_tz":300,"elapsed":27,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"outputs":[],"source":["# Define preprocessing transformations\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ZB0xRJO70bfe","executionInfo":{"status":"ok","timestamp":1750088237167,"user_tz":300,"elapsed":1,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"outputs":[],"source":["def walk_through_dir(dir_path):\n","\n","  for dirpath, dirnames, filenames in os.walk(dir_path):\n","    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"c0LQ1Ufgw8RB","executionInfo":{"status":"ok","timestamp":1750088237245,"user_tz":300,"elapsed":77,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"outputs":[],"source":["# Load source dataset (Caltech-10 subset)\n","source_dataset = datasets.ImageFolder(root=source_path, transform=transform)\n","source_loader = DataLoader(source_dataset, batch_size=64, shuffle=True)\n","\n","\n","target_dataset = datasets.ImageFolder(root=target_amazon_path, transform=transform)\n","target_loader = DataLoader(target_dataset, batch_size=64, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"k9liNl5s147i"},"source":["**Feature extraction**"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"zUmKsdur174R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750088238460,"user_tz":300,"elapsed":1212,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}},"outputId":"2304efd9-a4c0-4c5a-d6e4-67b2729c0c0b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 225MB/s]\n"]}],"source":["# Load a pretrained ResNet model\n","resnet50 = models.resnet50(pretrained=True)\n","resnet50.fc = torch.nn.Identity()  # Remove the final classification layer\n","\n","resnet50 = resnet50.to(device)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"wvKPkWxo2O2g","executionInfo":{"status":"ok","timestamp":1750088238478,"user_tz":300,"elapsed":15,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"outputs":[],"source":["def extract_and_save_features(resnet, loader, device, save_dir, prefix=\"features\", return_labels=True):\n","\n","    os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists\n","\n","    all_features, all_labels = [], []\n","    resnet.eval()\n","\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images = images.to(device)\n","            features = resnet(images).view(images.size(0), -1).cpu()\n","            all_features.append(features)\n","            if return_labels:\n","                all_labels.append(labels)\n","\n","    features_tensor = torch.cat(all_features)\n","    torch.save(features_tensor, os.path.join(save_dir, f\"{prefix}_features.pt\"))\n","    print(f\" Features saved to {os.path.join(save_dir, f'{prefix}_features.pt')}\")\n","\n","    if return_labels:\n","        labels_tensor = torch.cat(all_labels)\n","        torch.save(labels_tensor, os.path.join(save_dir, f\"{prefix}_labels.pt\"))\n","        print(f\" Labels saved to {os.path.join(save_dir, f'{prefix}_labels.pt')}\")\n","\n","    return (features_tensor, labels_tensor) if return_labels else features_tensor\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"mXRf1QNe2ncw","executionInfo":{"status":"ok","timestamp":1750088238492,"user_tz":300,"elapsed":9,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"outputs":[],"source":["save_path = '/content/drive/MyDrive/saved_resnet50_features'"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"1Dy-9dax2pi8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750088252550,"user_tz":300,"elapsed":14057,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}},"outputId":"f71833e4-e47c-433d-cfe0-9db605f3ae38"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Features saved to /content/drive/MyDrive/saved_resnet50_features/target_features.pt\n","Extracted Office Features Shape: torch.Size([2817, 2048])\n"]}],"source":["# For unlabeled target data\n","target_features = extract_and_save_features(resnet50, target_loader, device,\n","                          save_dir=save_path, prefix=\"target\", return_labels=False)\n","print(\"Extracted Office Features Shape:\", target_features.shape)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"1Wg7KuE72xXQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750088572038,"user_tz":300,"elapsed":319485,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}},"outputId":"972ca397-435e-4b67-d43a-4713e97ac91e"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Features saved to /content/drive/MyDrive/saved_resnet50_features/source_features.pt\n"," Labels saved to /content/drive/MyDrive/saved_resnet50_features/source_labels.pt\n","source_features torch.Size([61214, 2048])\n","source_labels torch.Size([61214])\n"]}],"source":["# For source features\n","source_features, source_labels = extract_and_save_features(resnet50, source_loader, device,\n","                          save_dir=save_path, prefix=\"source\")\n","\n","print('source_features', source_features.shape)\n","print('source_labels', source_labels.shape)"]},{"cell_type":"markdown","metadata":{"id":"Tg93TCintgjP"},"source":["**Train Classifier on Source Domain**"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"JAmFLKqith-_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750089026390,"user_tz":300,"elapsed":4384,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}},"outputId":"2463ecc9-3370-4794-e669-a689ec615a75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 5/100, Loss: 1.9428\n","Epoch 10/100, Loss: 1.4269\n","Epoch 15/100, Loss: 1.1070\n","Epoch 20/100, Loss: 0.9357\n","Epoch 25/100, Loss: 0.8483\n","Epoch 30/100, Loss: 0.8025\n","Epoch 35/100, Loss: 0.7770\n","Epoch 40/100, Loss: 0.7618\n","Epoch 45/100, Loss: 0.7520\n","Epoch 50/100, Loss: 0.7452\n","Epoch 55/100, Loss: 0.7403\n","Epoch 60/100, Loss: 0.7365\n","Epoch 65/100, Loss: 0.7335\n","Epoch 70/100, Loss: 0.7310\n","Epoch 75/100, Loss: 0.7289\n","Epoch 80/100, Loss: 0.7270\n","Epoch 85/100, Loss: 0.7254\n","Epoch 90/100, Loss: 0.7239\n","Epoch 95/100, Loss: 0.7225\n","Epoch 100/100, Loss: 0.7213\n"]}],"source":["num_source_classes = 10\n","num_epochs = 100\n","\n","\n","input_dim = source_features.shape[1]\n","classifier = nn.Linear(input_dim, num_source_classes)\n","optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n","\n","# Simple supervised classification on source\n","for epoch in range(num_epochs):\n","    logits = classifier(source_features)\n","    loss = nn.CrossEntropyLoss()(logits, source_labels)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    # Print loss every 5 epochs\n","    if (epoch + 1) % 5 == 0:\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2g__2gjUtm-Q"},"source":["**Generate Pseudo-Labels on Target**"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"OlIqYth1toNj","executionInfo":{"status":"ok","timestamp":1750089028562,"user_tz":300,"elapsed":5,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"outputs":[],"source":["with torch.no_grad():\n","    target_logits = classifier(target_features)\n","    pseudo_labels = torch.argmax(target_logits, dim=1)\n","    confidences = torch.softmax(target_logits, dim=1).max(dim=1)[0]\n","\n","    # Optional: Keep only high-confidence predictions\n","    confidence_threshold = 0.3\n","    confident_mask = confidences > confidence_threshold\n"]},{"cell_type":"markdown","metadata":{"id":"iUEPwvSTtqSp"},"source":["**Initialize Class-wise Domain Discriminators**"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"9vCYzNejtvcc","executionInfo":{"status":"ok","timestamp":1750089029889,"user_tz":300,"elapsed":46,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, input_dim):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(input_dim, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 1)\n","        )\n","    def forward(self, x): return self.net(x)\n","\n","# One discriminator per class\n","discriminators = {\n","    c: Discriminator(input_dim).to(device) for c in range(num_source_classes)\n","}"]},{"cell_type":"markdown","metadata":{"id":"plgeezhntwFg"},"source":["**Adversarial Training (Per Class)**"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"vtFwk4x7t4cP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750089031099,"user_tz":300,"elapsed":283,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}},"outputId":"b6e5e35c-702c-497f-a373-22a5669b82cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Trained discriminator for class 0 | src: 30607, tgt: 1106, loss: 0.6472\n","Trained discriminator for class 1 | src: 30607, tgt: 1711, loss: 0.6960\n","Skipping class 2: not enough samples (src: 0, tgt: 0)\n","Skipping class 3: not enough samples (src: 0, tgt: 0)\n","Skipping class 4: not enough samples (src: 0, tgt: 0)\n","Skipping class 5: not enough samples (src: 0, tgt: 0)\n","Skipping class 6: not enough samples (src: 0, tgt: 0)\n","Skipping class 7: not enough samples (src: 0, tgt: 0)\n","Skipping class 8: not enough samples (src: 0, tgt: 0)\n","Skipping class 9: not enough samples (src: 0, tgt: 0)\n"]}],"source":["for class_idx in range(num_source_classes):\n","    D = discriminators[class_idx]\n","    optimizer_D = torch.optim.Adam(D.parameters(), lr=1e-4)\n","\n","    # Select class-specific features\n","    src_mask = (source_labels == class_idx)\n","    tgt_mask = (pseudo_labels == class_idx) & confident_mask\n","\n","    src_feat = source_features[src_mask]\n","    tgt_feat = target_features[tgt_mask]\n","\n","    if src_feat.size(0) == 0 or tgt_feat.size(0) == 0:\n","        print(f\"Skipping class {class_idx}: not enough samples (src: {src_feat.size(0)}, tgt: {tgt_feat.size(0)})\")\n","        continue\n","\n","    all_feat = torch.cat([src_feat, tgt_feat], dim=0).to(device)\n","    domain_labels = torch.cat([\n","        torch.ones(src_feat.size(0)),\n","        torch.zeros(tgt_feat.size(0))\n","    ]).to(device)\n","\n","    domain_preds = D(all_feat).squeeze()\n","    adv_loss = F.binary_cross_entropy_with_logits(domain_preds, domain_labels)\n","\n","    optimizer_D.zero_grad()\n","    adv_loss.backward()\n","    optimizer_D.step()\n","\n","    print(f\"Trained discriminator for class {class_idx} | \"\n","          f\"src: {src_feat.size(0)}, tgt: {tgt_feat.size(0)}, \"\n","          f\"loss: {adv_loss.item():.4f}\")\n"]},{"cell_type":"markdown","source":["**Possible Causes:**\n","\n","**Classifier bias toward a few classes**\n","\n","Your classifier might be overfitting to dominant classes in Caltech-10, ignoring others when assigning pseudo-labels.\n","\n","Some classes may have lower feature separability, making the softmax outputs less confident.\n","\n","**Target domain shift**\n","\n","Domain shift causes category mismatch—even if some objects in Office-31 belong to a \"shared\" class, the visual domain is different enough that your classifier might not recognize them confidently.\n","\n","**Confidence threshold cutting too aggressively**\n","\n","If your threshold (confidence_threshold = 0.7) is too high, most target samples won’t qualify as confidently pseudo-labeled.\n","\n","Lowering it to 0.5 or even 0.3 might help populate more classes.\n"],"metadata":{"id":"jOfUPOmLawW6"}}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"mount_file_id":"1KRgIEozc_3BaPwKYOquS1GWiQ3rnEiFO","authorship_tag":"ABX9TyODvxNFmXBozP8Q5GIBlIE2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}